{
    "model_name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "seq_length": 768,
    "max_length": 768,
    "raw_data_path": "./raw_data/katchers/single/",
    "build_dataset": false,
    "dataset_path": "./datasets/katchers/single/",
    "build_split": "val",
    "merge_with_final_checkpoint": false,
    "model_type": "llama2",
    "output_dir": "./output/rec-sys-llm-single-tuning",
    "run_name": "rec-sys-llm-single-tuning",
    "num_train_epochs": 10,
    "logging_steps":200,
    "per_device_train_batch_size":4,
    "per_device_eval_batch_size":4,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "learning_rate": 1e-4,
    "lr_scheduler_type": "cosine",
    "warmup_ratio": 0.03,
    "max_grad_norm": 0.3,
    "weight_decay": 0.05,
    "save_total_limit": 10,
    "save_strategy": "epoch",
    "evaluation_strategy": "epoch",
    "load_best_model_at_end": true,
    "greater_is_better": true,
    "optim": "paged_adamw_32bit",
    "bf16": true,
    "remove_unused_columns": false,
    "report_to": "wandb"

}
